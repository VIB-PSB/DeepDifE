{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/DeepDifE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 15:25:16.110674: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 15:25:16.166949: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-05 15:25:16.168233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-05 15:25:16.937966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd ..\n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import esparto\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evoaug_tf import evoaug, augment\n",
    "from src.diff_expression_model import get_model, get_siamese_model, post_hoc_conjoining, get_auroc\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we start from this data pickle as I'm not aware how Helder did DE analysis and generated the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath = \"data/dataset_solid_chrome.pkl\"\n",
    "with open(ppath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    1900\n",
       "valid     257\n",
       "test      241\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"set\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how to subdivide the dataset into train-test split we only take the following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.reset_index()\n",
    "dataset = dataset[[\"geneID\", \"Category\", \"GeneFamily\", \"seqs\"]]\n",
    "dataset.rename(columns={\"geneID\":\"GeneID\", \"Category\":\"Label\", \"seqs\": \"Sequence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...  \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...  \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...  \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...  \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...  \n",
       "...                                                 ...  \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...  \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...  \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...  \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...  \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...  \n",
       "\n",
       "[2398 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encode & reverse-complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import one_hot_encode_series, reverse_complement_series, reverse_complement_sequence\n",
    "dataset[\"One_hot_encoded\"] = one_hot_encode_series(dataset[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"RC_one_hot_encoded\"] = reverse_complement_series(dataset[\"One_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>One_hot_encoded</th>\n",
       "      <th>RC_one_hot_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "      <td>[[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \\\n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...   \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...   \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...   \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...   \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...   \n",
       "...                                                 ...   \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...   \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...   \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...   \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...   \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...   \n",
       "\n",
       "                                        One_hot_encoded  \\\n",
       "0     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "1     [[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...   \n",
       "2     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...   \n",
       "3     [[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...   \n",
       "4     [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...   \n",
       "...                                                 ...   \n",
       "2393  [[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "2394  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "2395  [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...   \n",
       "2396  [[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...   \n",
       "2397  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "\n",
       "                                     RC_one_hot_encoded  \n",
       "0     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "1     [[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2     [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "3     [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...  \n",
       "4     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...  \n",
       "...                                                 ...  \n",
       "2393  [[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...  \n",
       "2394  [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2395  [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "2396  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...  \n",
       "2397  [[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...  \n",
       "\n",
       "[2398 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import grouped_shuffle_split\n",
    "train_df, validation_test_df = grouped_shuffle_split(dataset, dataset[\"GeneFamily\"], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df, test_df  = grouped_shuffle_split(validation_test_df, validation_test_df[\"GeneFamily\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 1900\n",
      "Length of validation set: 257\n",
      "Length of test set: 241\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training set: {train_df.shape[0]}\")\n",
    "print(f\"Length of validation set: {validation_df.shape[0]}\")\n",
    "print(f\"Length of test set: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_and_labels(df):\n",
    "\tohe_np = np.stack(df[\"One_hot_encoded\"])\n",
    "\trc_np = np.stack(df[\"RC_one_hot_encoded\"])\n",
    "\n",
    "\tx = np.append(ohe_np, rc_np, axis=0)\n",
    "\tx = x.astype('float32')\n",
    "\ty = np.append(df[\"Label\"], df[\"Label\"])\n",
    "\treturn x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_input_and_labels(train_df)\n",
    "x_validation, y_validation = get_input_and_labels(validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model uses evo augmentation, a list of possible nucleotide operations needs to be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_list = [\n",
    "    augment.RandomRC(rc_prob=0.5),\n",
    "    augment.RandomInsertionBatch(insert_min=0, insert_max=20),\n",
    "    augment.RandomDeletion(delete_min=0, delete_max=30),\n",
    "    augment.RandomTranslocationBatch(shift_min=0, shift_max=20),\n",
    "    augment.RandomMutation(mutate_frac=0.05),\n",
    "    augment.RandomNoise()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the shape of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_df[\"One_hot_encoded\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=input_shape, perform_evoaug=True, augment_list=augment_list ,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\tpatience=20,\n",
    "\t\t\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
    "# reduce learning rate callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tfactor=0.1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=1e-7,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tverbose=1)\n",
    "callbacks = [early_stopping_callback, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "38/38 [==============================] - 5s 36ms/step - loss: 0.6951 - acc: 0.4979 - auROC: 0.4944 - auPRC: 0.4940 - true_positives: 670.0000 - val_loss: 0.6938 - val_acc: 0.5019 - val_auROC: 0.5153 - val_auPRC: 0.5083 - val_true_positives: 258.0000 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6945 - acc: 0.4911 - auROC: 0.4872 - auPRC: 0.4794 - true_positives: 599.0000 - val_loss: 0.6931 - val_acc: 0.5000 - val_auROC: 0.5469 - val_auPRC: 0.5445 - val_true_positives: 1.0000 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6939 - acc: 0.5134 - auROC: 0.5120 - auPRC: 0.5091 - true_positives: 926.0000 - val_loss: 0.6922 - val_acc: 0.5370 - val_auROC: 0.5969 - val_auPRC: 0.5859 - val_true_positives: 52.0000 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.6912 - acc: 0.5250 - auROC: 0.5458 - auPRC: 0.5228 - true_positives: 641.0000 - val_loss: 0.6854 - val_acc: 0.5856 - val_auROC: 0.6404 - val_auPRC: 0.6042 - val_true_positives: 170.0000 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6880 - acc: 0.5429 - auROC: 0.5579 - auPRC: 0.5363 - true_positives: 1147.0000 - val_loss: 0.6808 - val_acc: 0.6031 - val_auROC: 0.6403 - val_auPRC: 0.6339 - val_true_positives: 120.0000 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.6761 - acc: 0.5653 - auROC: 0.5993 - auPRC: 0.5618 - true_positives: 1013.0000 - val_loss: 0.6681 - val_acc: 0.6070 - val_auROC: 0.6484 - val_auPRC: 0.6259 - val_true_positives: 215.0000 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.6777 - acc: 0.5642 - auROC: 0.5966 - auPRC: 0.5653 - true_positives: 1267.0000 - val_loss: 0.6674 - val_acc: 0.5953 - val_auROC: 0.6433 - val_auPRC: 0.5996 - val_true_positives: 162.0000 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6724 - acc: 0.5824 - auROC: 0.6137 - auPRC: 0.5775 - true_positives: 1278.0000 - val_loss: 0.6819 - val_acc: 0.5428 - val_auROC: 0.6474 - val_auPRC: 0.6133 - val_true_positives: 242.0000 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6732 - acc: 0.5705 - auROC: 0.6044 - auPRC: 0.5766 - true_positives: 1245.0000 - val_loss: 0.6850 - val_acc: 0.5564 - val_auROC: 0.6029 - val_auPRC: 0.5718 - val_true_positives: 240.0000 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.6684 - acc: 0.5853 - auROC: 0.6231 - auPRC: 0.5891 - true_positives: 1154.0000 - val_loss: 0.6594 - val_acc: 0.6051 - val_auROC: 0.6597 - val_auPRC: 0.6179 - val_true_positives: 168.0000 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6599 - acc: 0.6082 - auROC: 0.6430 - auPRC: 0.6124 - true_positives: 1250.0000 - val_loss: 0.6595 - val_acc: 0.6167 - val_auROC: 0.6587 - val_auPRC: 0.6216 - val_true_positives: 196.0000 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6554 - acc: 0.6163 - auROC: 0.6516 - auPRC: 0.6091 - true_positives: 1304.0000 - val_loss: 0.6710 - val_acc: 0.5837 - val_auROC: 0.6594 - val_auPRC: 0.6228 - val_true_positives: 234.0000 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6561 - acc: 0.6089 - auROC: 0.6512 - auPRC: 0.6156 - true_positives: 1344.0000 - val_loss: 0.6723 - val_acc: 0.6012 - val_auROC: 0.6598 - val_auPRC: 0.6184 - val_true_positives: 235.0000 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6488 - acc: 0.6221 - auROC: 0.6698 - auPRC: 0.6277 - true_positives: 1234.0000 - val_loss: 0.6484 - val_acc: 0.6128 - val_auROC: 0.6812 - val_auPRC: 0.6468 - val_true_positives: 197.0000 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6374 - acc: 0.6337 - auROC: 0.6855 - auPRC: 0.6493 - true_positives: 1299.0000 - val_loss: 0.6475 - val_acc: 0.6167 - val_auROC: 0.6923 - val_auPRC: 0.6635 - val_true_positives: 209.0000 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6417 - acc: 0.6334 - auROC: 0.6778 - auPRC: 0.6405 - true_positives: 1284.0000 - val_loss: 0.6681 - val_acc: 0.6031 - val_auROC: 0.6789 - val_auPRC: 0.6452 - val_true_positives: 234.0000 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6321 - acc: 0.6416 - auROC: 0.6936 - auPRC: 0.6524 - true_positives: 1292.0000 - val_loss: 0.6694 - val_acc: 0.6070 - val_auROC: 0.6789 - val_auPRC: 0.6438 - val_true_positives: 235.0000 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.6330 - acc: 0.6426 - auROC: 0.6936 - auPRC: 0.6513 - true_positives: 1328.0000 - val_loss: 0.6334 - val_acc: 0.6479 - val_auROC: 0.7054 - val_auPRC: 0.6794 - val_true_positives: 206.0000 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6203 - acc: 0.6524 - auROC: 0.7084 - auPRC: 0.6671 - true_positives: 1305.0000 - val_loss: 0.6310 - val_acc: 0.6440 - val_auROC: 0.7145 - val_auPRC: 0.6994 - val_true_positives: 210.0000 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6240 - acc: 0.6534 - auROC: 0.7077 - auPRC: 0.6718 - true_positives: 1309.0000 - val_loss: 0.6285 - val_acc: 0.6576 - val_auROC: 0.7119 - val_auPRC: 0.6969 - val_true_positives: 206.0000 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6074 - acc: 0.6755 - auROC: 0.7326 - auPRC: 0.6981 - true_positives: 1330.0000 - val_loss: 0.6284 - val_acc: 0.6518 - val_auROC: 0.7214 - val_auPRC: 0.6996 - val_true_positives: 224.0000 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6118 - acc: 0.6653 - auROC: 0.7247 - auPRC: 0.6841 - true_positives: 1350.0000 - val_loss: 0.6304 - val_acc: 0.6440 - val_auROC: 0.7204 - val_auPRC: 0.6951 - val_true_positives: 225.0000 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6012 - acc: 0.6739 - auROC: 0.7377 - auPRC: 0.7196 - true_positives: 1325.0000 - val_loss: 0.6274 - val_acc: 0.6595 - val_auROC: 0.7214 - val_auPRC: 0.6978 - val_true_positives: 221.0000 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6089 - acc: 0.6692 - auROC: 0.7268 - auPRC: 0.7002 - true_positives: 1350.0000 - val_loss: 0.6244 - val_acc: 0.6576 - val_auROC: 0.7175 - val_auPRC: 0.6861 - val_true_positives: 216.0000 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.6049 - acc: 0.6682 - auROC: 0.7316 - auPRC: 0.7014 - true_positives: 1337.0000 - val_loss: 0.6142 - val_acc: 0.6712 - val_auROC: 0.7278 - val_auPRC: 0.7056 - val_true_positives: 215.0000 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5949 - acc: 0.6811 - auROC: 0.7445 - auPRC: 0.7188 - true_positives: 1324.0000 - val_loss: 0.6044 - val_acc: 0.6595 - val_auROC: 0.7378 - val_auPRC: 0.7198 - val_true_positives: 160.0000 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5951 - acc: 0.6795 - auROC: 0.7451 - auPRC: 0.7265 - true_positives: 1329.0000 - val_loss: 0.6342 - val_acc: 0.6381 - val_auROC: 0.7136 - val_auPRC: 0.6996 - val_true_positives: 230.0000 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5913 - acc: 0.6797 - auROC: 0.7490 - auPRC: 0.7262 - true_positives: 1350.0000 - val_loss: 0.6171 - val_acc: 0.6459 - val_auROC: 0.7412 - val_auPRC: 0.7254 - val_true_positives: 134.0000 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5957 - acc: 0.6729 - auROC: 0.7441 - auPRC: 0.7171 - true_positives: 1337.0000 - val_loss: 0.6066 - val_acc: 0.6790 - val_auROC: 0.7328 - val_auPRC: 0.7138 - val_true_positives: 215.0000 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5823 - acc: 0.6882 - auROC: 0.7554 - auPRC: 0.7330 - true_positives: 1364.0000 - val_loss: 0.5957 - val_acc: 0.6732 - val_auROC: 0.7382 - val_auPRC: 0.7199 - val_true_positives: 189.0000 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5748 - acc: 0.6955 - auROC: 0.7663 - auPRC: 0.7501 - true_positives: 1380.0000 - val_loss: 0.6045 - val_acc: 0.6732 - val_auROC: 0.7473 - val_auPRC: 0.7347 - val_true_positives: 154.0000 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5933 - acc: 0.6832 - auROC: 0.7467 - auPRC: 0.7292 - true_positives: 1309.0000 - val_loss: 0.5990 - val_acc: 0.6809 - val_auROC: 0.7423 - val_auPRC: 0.7256 - val_true_positives: 218.0000 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5707 - acc: 0.7003 - auROC: 0.7741 - auPRC: 0.7569 - true_positives: 1354.0000 - val_loss: 0.5884 - val_acc: 0.6965 - val_auROC: 0.7499 - val_auPRC: 0.7306 - val_true_positives: 192.0000 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5727 - acc: 0.7034 - auROC: 0.7702 - auPRC: 0.7461 - true_positives: 1365.0000 - val_loss: 0.5970 - val_acc: 0.6790 - val_auROC: 0.7406 - val_auPRC: 0.7284 - val_true_positives: 203.0000 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5612 - acc: 0.7003 - auROC: 0.7789 - auPRC: 0.7636 - true_positives: 1376.0000 - val_loss: 0.5818 - val_acc: 0.7023 - val_auROC: 0.7601 - val_auPRC: 0.7529 - val_true_positives: 186.0000 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5628 - acc: 0.7058 - auROC: 0.7790 - auPRC: 0.7627 - true_positives: 1384.0000 - val_loss: 0.5902 - val_acc: 0.6770 - val_auROC: 0.7505 - val_auPRC: 0.7425 - val_true_positives: 206.0000 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5674 - acc: 0.7066 - auROC: 0.7756 - auPRC: 0.7614 - true_positives: 1383.0000 - val_loss: 0.5866 - val_acc: 0.6907 - val_auROC: 0.7545 - val_auPRC: 0.7473 - val_true_positives: 179.0000 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5462 - acc: 0.7100 - auROC: 0.7934 - auPRC: 0.7866 - true_positives: 1345.0000 - val_loss: 0.5875 - val_acc: 0.6790 - val_auROC: 0.7472 - val_auPRC: 0.7378 - val_true_positives: 201.0000 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5550 - acc: 0.7089 - auROC: 0.7865 - auPRC: 0.7700 - true_positives: 1369.0000 - val_loss: 0.5838 - val_acc: 0.6790 - val_auROC: 0.7580 - val_auPRC: 0.7489 - val_true_positives: 169.0000 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5553 - acc: 0.7050 - auROC: 0.7836 - auPRC: 0.7745 - true_positives: 1360.0000\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5553 - acc: 0.7050 - auROC: 0.7836 - auPRC: 0.7745 - true_positives: 1360.0000 - val_loss: 0.6118 - val_acc: 0.6595 - val_auROC: 0.7251 - val_auPRC: 0.7166 - val_true_positives: 224.0000 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5533 - acc: 0.7111 - auROC: 0.7913 - auPRC: 0.7814 - true_positives: 1413.0000 - val_loss: 0.5835 - val_acc: 0.6907 - val_auROC: 0.7536 - val_auPRC: 0.7409 - val_true_positives: 195.0000 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5602 - acc: 0.7087 - auROC: 0.7809 - auPRC: 0.7657 - true_positives: 1388.0000 - val_loss: 0.5819 - val_acc: 0.6809 - val_auROC: 0.7579 - val_auPRC: 0.7464 - val_true_positives: 175.0000 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5530 - acc: 0.7108 - auROC: 0.7900 - auPRC: 0.7755 - true_positives: 1342.0000 - val_loss: 0.5840 - val_acc: 0.6829 - val_auROC: 0.7496 - val_auPRC: 0.7378 - val_true_positives: 202.0000 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5493 - acc: 0.7192 - auROC: 0.7912 - auPRC: 0.7809 - true_positives: 1391.0000 - val_loss: 0.5807 - val_acc: 0.6887 - val_auROC: 0.7540 - val_auPRC: 0.7419 - val_true_positives: 204.0000 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5434 - acc: 0.7282 - auROC: 0.7975 - auPRC: 0.7824 - true_positives: 1404.0000 - val_loss: 0.5813 - val_acc: 0.6868 - val_auROC: 0.7541 - val_auPRC: 0.7433 - val_true_positives: 207.0000 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5430 - acc: 0.7192 - auROC: 0.7975 - auPRC: 0.7878 - true_positives: 1413.0000 - val_loss: 0.5827 - val_acc: 0.6965 - val_auROC: 0.7540 - val_auPRC: 0.7449 - val_true_positives: 205.0000 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5312 - acc: 0.7297 - auROC: 0.8092 - auPRC: 0.7959 - true_positives: 1408.0000 - val_loss: 0.5819 - val_acc: 0.6926 - val_auROC: 0.7558 - val_auPRC: 0.7471 - val_true_positives: 212.0000 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5454 - acc: 0.7211 - auROC: 0.7965 - auPRC: 0.7828 - true_positives: 1400.0000 - val_loss: 0.5874 - val_acc: 0.6829 - val_auROC: 0.7471 - val_auPRC: 0.7389 - val_true_positives: 212.0000 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5520 - acc: 0.7176 - auROC: 0.7897 - auPRC: 0.7757 - true_positives: 1397.0000\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5520 - acc: 0.7176 - auROC: 0.7897 - auPRC: 0.7757 - true_positives: 1397.0000 - val_loss: 0.5840 - val_acc: 0.6790 - val_auROC: 0.7522 - val_auPRC: 0.7433 - val_true_positives: 206.0000 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 1s 19ms/step - loss: 0.5307 - acc: 0.7337 - auROC: 0.8079 - auPRC: 0.7990 - true_positives: 1449.0000 - val_loss: 0.5792 - val_acc: 0.6926 - val_auROC: 0.7582 - val_auPRC: 0.7457 - val_true_positives: 207.0000 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5426 - acc: 0.7268 - auROC: 0.7997 - auPRC: 0.7813 - true_positives: 1420.0000 - val_loss: 0.5821 - val_acc: 0.6868 - val_auROC: 0.7549 - val_auPRC: 0.7459 - val_true_positives: 204.0000 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5337 - acc: 0.7329 - auROC: 0.8059 - auPRC: 0.7936 - true_positives: 1423.0000 - val_loss: 0.5788 - val_acc: 0.6907 - val_auROC: 0.7590 - val_auPRC: 0.7487 - val_true_positives: 204.0000 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5331 - acc: 0.7266 - auROC: 0.8047 - auPRC: 0.7953 - true_positives: 1400.0000 - val_loss: 0.5808 - val_acc: 0.6887 - val_auROC: 0.7541 - val_auPRC: 0.7435 - val_true_positives: 201.0000 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5470 - acc: 0.7232 - auROC: 0.7956 - auPRC: 0.7805 - true_positives: 1411.0000 - val_loss: 0.5816 - val_acc: 0.6868 - val_auROC: 0.7543 - val_auPRC: 0.7439 - val_true_positives: 206.0000 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5351 - acc: 0.7305 - auROC: 0.8030 - auPRC: 0.7892 - true_positives: 1417.0000 - val_loss: 0.5852 - val_acc: 0.6887 - val_auROC: 0.7489 - val_auPRC: 0.7367 - val_true_positives: 208.0000 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5341 - acc: 0.7318 - auROC: 0.8055 - auPRC: 0.7954 - true_positives: 1432.0000 - val_loss: 0.5814 - val_acc: 0.6887 - val_auROC: 0.7552 - val_auPRC: 0.7445 - val_true_positives: 204.0000 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "36/38 [===========================>..] - ETA: 0s - loss: 0.5367 - acc: 0.7306 - auROC: 0.8025 - auPRC: 0.7914 - true_positives: 1339.0000\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5346 - acc: 0.7329 - auROC: 0.8046 - auPRC: 0.7930 - true_positives: 1419.0000 - val_loss: 0.5837 - val_acc: 0.6848 - val_auROC: 0.7536 - val_auPRC: 0.7447 - val_true_positives: 205.0000 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5404 - acc: 0.7226 - auROC: 0.7995 - auPRC: 0.7890 - true_positives: 1411.0000 - val_loss: 0.5840 - val_acc: 0.6848 - val_auROC: 0.7498 - val_auPRC: 0.7394 - val_true_positives: 210.0000 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5353 - acc: 0.7303 - auROC: 0.8054 - auPRC: 0.7946 - true_positives: 1420.0000 - val_loss: 0.5823 - val_acc: 0.6829 - val_auROC: 0.7538 - val_auPRC: 0.7453 - val_true_positives: 201.0000 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5345 - acc: 0.7366 - auROC: 0.8061 - auPRC: 0.7929 - true_positives: 1463.0000 - val_loss: 0.5814 - val_acc: 0.6848 - val_auROC: 0.7559 - val_auPRC: 0.7459 - val_true_positives: 203.0000 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5453 - acc: 0.7253 - auROC: 0.7987 - auPRC: 0.7867 - true_positives: 1409.0000 - val_loss: 0.5822 - val_acc: 0.6946 - val_auROC: 0.7533 - val_auPRC: 0.7418 - val_true_positives: 209.0000 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.5443 - acc: 0.7211 - auROC: 0.7960 - auPRC: 0.7875 - true_positives: 1332.0000\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5450 - acc: 0.7208 - auROC: 0.7952 - auPRC: 0.7874 - true_positives: 1370.0000 - val_loss: 0.5812 - val_acc: 0.6946 - val_auROC: 0.7555 - val_auPRC: 0.7433 - val_true_positives: 207.0000 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5323 - acc: 0.7239 - auROC: 0.8075 - auPRC: 0.7965 - true_positives: 1404.0000 - val_loss: 0.5833 - val_acc: 0.6868 - val_auROC: 0.7533 - val_auPRC: 0.7414 - val_true_positives: 205.0000 - lr: 1.0000e-07\n",
      "Epoch 64/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5454 - acc: 0.7203 - auROC: 0.7935 - auPRC: 0.7770 - true_positives: 1401.0000 - val_loss: 0.5807 - val_acc: 0.7062 - val_auROC: 0.7551 - val_auPRC: 0.7435 - val_true_positives: 211.0000 - lr: 1.0000e-07\n",
      "Epoch 65/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5425 - acc: 0.7168 - auROC: 0.7978 - auPRC: 0.7871 - true_positives: 1399.0000 - val_loss: 0.5824 - val_acc: 0.7023 - val_auROC: 0.7514 - val_auPRC: 0.7393 - val_true_positives: 210.0000 - lr: 1.0000e-07\n",
      "Epoch 66/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5387 - acc: 0.7161 - auROC: 0.8012 - auPRC: 0.7922 - true_positives: 1399.0000 - val_loss: 0.5840 - val_acc: 0.6868 - val_auROC: 0.7514 - val_auPRC: 0.7422 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 67/100\n",
      "37/38 [============================>.] - ETA: 0s - loss: 0.5409 - acc: 0.7246 - auROC: 0.8013 - auPRC: 0.7858 - true_positives: 1358.0000\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5418 - acc: 0.7232 - auROC: 0.8002 - auPRC: 0.7848 - true_positives: 1394.0000 - val_loss: 0.5851 - val_acc: 0.6848 - val_auROC: 0.7481 - val_auPRC: 0.7370 - val_true_positives: 204.0000 - lr: 1.0000e-07\n",
      "Epoch 68/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5305 - acc: 0.7379 - auROC: 0.8103 - auPRC: 0.7957 - true_positives: 1420.0000 - val_loss: 0.5798 - val_acc: 0.6926 - val_auROC: 0.7545 - val_auPRC: 0.7440 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 69/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5296 - acc: 0.7295 - auROC: 0.8099 - auPRC: 0.7985 - true_positives: 1417.0000 - val_loss: 0.5842 - val_acc: 0.6829 - val_auROC: 0.7518 - val_auPRC: 0.7397 - val_true_positives: 204.0000 - lr: 1.0000e-07\n",
      "Epoch 70/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5406 - acc: 0.7232 - auROC: 0.8005 - auPRC: 0.7891 - true_positives: 1406.0000 - val_loss: 0.5821 - val_acc: 0.7004 - val_auROC: 0.7526 - val_auPRC: 0.7421 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 71/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5328 - acc: 0.7313 - auROC: 0.8080 - auPRC: 0.7919 - true_positives: 1415.0000 - val_loss: 0.5858 - val_acc: 0.6868 - val_auROC: 0.7469 - val_auPRC: 0.7377 - val_true_positives: 205.0000 - lr: 1.0000e-07\n",
      "Epoch 72/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5367 - acc: 0.7187 - auROC: 0.8022 - auPRC: 0.7930 - true_positives: 1387.0000 - val_loss: 0.5787 - val_acc: 0.6907 - val_auROC: 0.7595 - val_auPRC: 0.7494 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 73/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5451 - acc: 0.7187 - auROC: 0.7973 - auPRC: 0.7835 - true_positives: 1411.0000 - val_loss: 0.5862 - val_acc: 0.6907 - val_auROC: 0.7461 - val_auPRC: 0.7312 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 74/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5329 - acc: 0.7234 - auROC: 0.8058 - auPRC: 0.7949 - true_positives: 1422.0000 - val_loss: 0.5832 - val_acc: 0.6809 - val_auROC: 0.7534 - val_auPRC: 0.7443 - val_true_positives: 203.0000 - lr: 1.0000e-07\n",
      "Epoch 75/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5538 - acc: 0.7082 - auROC: 0.7869 - auPRC: 0.7740 - true_positives: 1358.0000 - val_loss: 0.5865 - val_acc: 0.6887 - val_auROC: 0.7483 - val_auPRC: 0.7380 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 76/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5342 - acc: 0.7308 - auROC: 0.8051 - auPRC: 0.7921 - true_positives: 1412.0000 - val_loss: 0.5809 - val_acc: 0.6926 - val_auROC: 0.7548 - val_auPRC: 0.7430 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 77/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5382 - acc: 0.7268 - auROC: 0.8012 - auPRC: 0.7891 - true_positives: 1405.0000 - val_loss: 0.5830 - val_acc: 0.6946 - val_auROC: 0.7528 - val_auPRC: 0.7419 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 78/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5471 - acc: 0.7184 - auROC: 0.7928 - auPRC: 0.7741 - true_positives: 1385.0000 - val_loss: 0.5816 - val_acc: 0.6848 - val_auROC: 0.7555 - val_auPRC: 0.7450 - val_true_positives: 202.0000 - lr: 1.0000e-07\n",
      "Epoch 79/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5383 - acc: 0.7211 - auROC: 0.8002 - auPRC: 0.7887 - true_positives: 1405.0000 - val_loss: 0.5839 - val_acc: 0.6829 - val_auROC: 0.7508 - val_auPRC: 0.7384 - val_true_positives: 204.0000 - lr: 1.0000e-07\n",
      "Epoch 80/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.5363 - acc: 0.7295 - auROC: 0.8050 - auPRC: 0.7997 - true_positives: 1377.0000 - val_loss: 0.5839 - val_acc: 0.6809 - val_auROC: 0.7503 - val_auPRC: 0.7400 - val_true_positives: 205.0000 - lr: 1.0000e-07\n",
      "Epoch 81/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5377 - acc: 0.7184 - auROC: 0.8009 - auPRC: 0.7864 - true_positives: 1387.0000 - val_loss: 0.5806 - val_acc: 0.6965 - val_auROC: 0.7556 - val_auPRC: 0.7474 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 82/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5296 - acc: 0.7311 - auROC: 0.8099 - auPRC: 0.7988 - true_positives: 1429.0000 - val_loss: 0.5812 - val_acc: 0.6965 - val_auROC: 0.7539 - val_auPRC: 0.7448 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 83/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5422 - acc: 0.7171 - auROC: 0.7948 - auPRC: 0.7833 - true_positives: 1423.0000 - val_loss: 0.5810 - val_acc: 0.6984 - val_auROC: 0.7549 - val_auPRC: 0.7425 - val_true_positives: 209.0000 - lr: 1.0000e-07\n",
      "Epoch 84/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5513 - acc: 0.7116 - auROC: 0.7913 - auPRC: 0.7774 - true_positives: 1382.0000 - val_loss: 0.5810 - val_acc: 0.6926 - val_auROC: 0.7527 - val_auPRC: 0.7404 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 85/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5449 - acc: 0.7224 - auROC: 0.7969 - auPRC: 0.7833 - true_positives: 1412.0000 - val_loss: 0.5832 - val_acc: 0.6868 - val_auROC: 0.7513 - val_auPRC: 0.7395 - val_true_positives: 205.0000 - lr: 1.0000e-07\n",
      "Epoch 86/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5412 - acc: 0.7203 - auROC: 0.7972 - auPRC: 0.7863 - true_positives: 1409.0000 - val_loss: 0.5815 - val_acc: 0.6887 - val_auROC: 0.7530 - val_auPRC: 0.7410 - val_true_positives: 204.0000 - lr: 1.0000e-07\n",
      "Epoch 87/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5406 - acc: 0.7129 - auROC: 0.7977 - auPRC: 0.7887 - true_positives: 1368.0000 - val_loss: 0.5838 - val_acc: 0.6984 - val_auROC: 0.7521 - val_auPRC: 0.7406 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 88/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5413 - acc: 0.7224 - auROC: 0.7990 - auPRC: 0.7823 - true_positives: 1394.0000 - val_loss: 0.5815 - val_acc: 0.6907 - val_auROC: 0.7553 - val_auPRC: 0.7451 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 89/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5348 - acc: 0.7284 - auROC: 0.8061 - auPRC: 0.7897 - true_positives: 1405.0000 - val_loss: 0.5776 - val_acc: 0.6984 - val_auROC: 0.7576 - val_auPRC: 0.7457 - val_true_positives: 208.0000 - lr: 1.0000e-07\n",
      "Epoch 90/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5370 - acc: 0.7242 - auROC: 0.8021 - auPRC: 0.7892 - true_positives: 1384.0000 - val_loss: 0.5802 - val_acc: 0.6848 - val_auROC: 0.7571 - val_auPRC: 0.7478 - val_true_positives: 203.0000 - lr: 1.0000e-07\n",
      "Epoch 91/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5347 - acc: 0.7237 - auROC: 0.8066 - auPRC: 0.8006 - true_positives: 1399.0000 - val_loss: 0.5832 - val_acc: 0.6887 - val_auROC: 0.7517 - val_auPRC: 0.7384 - val_true_positives: 202.0000 - lr: 1.0000e-07\n",
      "Epoch 92/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5435 - acc: 0.7216 - auROC: 0.7999 - auPRC: 0.7885 - true_positives: 1399.0000 - val_loss: 0.5810 - val_acc: 0.6809 - val_auROC: 0.7593 - val_auPRC: 0.7465 - val_true_positives: 203.0000 - lr: 1.0000e-07\n",
      "Epoch 93/100\n",
      "38/38 [==============================] - 1s 22ms/step - loss: 0.5402 - acc: 0.7195 - auROC: 0.8006 - auPRC: 0.7866 - true_positives: 1401.0000 - val_loss: 0.5821 - val_acc: 0.6907 - val_auROC: 0.7523 - val_auPRC: 0.7422 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 94/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5501 - acc: 0.7176 - auROC: 0.7906 - auPRC: 0.7818 - true_positives: 1377.0000 - val_loss: 0.5818 - val_acc: 0.6946 - val_auROC: 0.7554 - val_auPRC: 0.7442 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 95/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5475 - acc: 0.7129 - auROC: 0.7947 - auPRC: 0.7825 - true_positives: 1396.0000 - val_loss: 0.5837 - val_acc: 0.6887 - val_auROC: 0.7500 - val_auPRC: 0.7379 - val_true_positives: 204.0000 - lr: 1.0000e-07\n",
      "Epoch 96/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5417 - acc: 0.7284 - auROC: 0.7991 - auPRC: 0.7883 - true_positives: 1410.0000 - val_loss: 0.5812 - val_acc: 0.6907 - val_auROC: 0.7537 - val_auPRC: 0.7421 - val_true_positives: 205.0000 - lr: 1.0000e-07\n",
      "Epoch 97/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5501 - acc: 0.7105 - auROC: 0.7895 - auPRC: 0.7782 - true_positives: 1410.0000 - val_loss: 0.5835 - val_acc: 0.6809 - val_auROC: 0.7513 - val_auPRC: 0.7411 - val_true_positives: 201.0000 - lr: 1.0000e-07\n",
      "Epoch 98/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5362 - acc: 0.7295 - auROC: 0.8030 - auPRC: 0.7904 - true_positives: 1426.0000 - val_loss: 0.5796 - val_acc: 0.6946 - val_auROC: 0.7586 - val_auPRC: 0.7469 - val_true_positives: 206.0000 - lr: 1.0000e-07\n",
      "Epoch 99/100\n",
      "38/38 [==============================] - 1s 21ms/step - loss: 0.5362 - acc: 0.7258 - auROC: 0.8046 - auPRC: 0.7922 - true_positives: 1414.0000 - val_loss: 0.5817 - val_acc: 0.6926 - val_auROC: 0.7537 - val_auPRC: 0.7431 - val_true_positives: 207.0000 - lr: 1.0000e-07\n",
      "Epoch 100/100\n",
      "38/38 [==============================] - 1s 20ms/step - loss: 0.5371 - acc: 0.7289 - auROC: 0.8049 - auPRC: 0.7949 - true_positives: 1422.0000 - val_loss: 0.5844 - val_acc: 0.6848 - val_auROC: 0.7477 - val_auPRC: 0.7384 - val_true_positives: 203.0000 - lr: 1.0000e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "\t\t\t\t\ty_train,\n",
    "\t\t\t\t\tepochs=100,\n",
    "\t\t\t\t\tbatch_size=100,\n",
    "\t\t\t\t\tvalidation_data=(x_validation, y_validation),\n",
    "\t\t\t\t\tcallbacks=callbacks\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform post-hoc conjoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = get_siamese_model(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.stack(test_df[\"One_hot_encoded\"])\n",
    "x_test_rc = np.stack(test_df[\"RC_one_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[\"Label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used evo aug in our model all the sequences which were trained on, were of length 620. We use the evoaug padding function to pad the test set to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = model._pad_end(x_test)\n",
    "x_test_rc = model._pad_end(x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_categories, predictions = post_hoc_conjoining(siamese_model, x_test, x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248787248787248"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auroc(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
