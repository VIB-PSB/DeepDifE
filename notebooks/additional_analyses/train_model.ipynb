{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/nas6/group/biocomp/projects/transreg/sathi/DeepDifE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 09:33:24.774236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/shared/apps/x86_64/dependencies_rl9:/software/shared/apps/x86_64/git/2.13.1/lib64/\n",
      "2024-07-08 09:33:24.774331: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-08 09:33:56.148515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/shared/apps/x86_64/dependencies_rl9:/software/shared/apps/x86_64/git/2.13.1/lib64/\n",
      "2024-07-08 09:33:56.148901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/shared/apps/x86_64/dependencies_rl9:/software/shared/apps/x86_64/git/2.13.1/lib64/\n",
      "2024-07-08 09:33:56.148951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /group/transreg/sathi/DeepDifE \n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import esparto\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evoaug_tf import evoaug, augment\n",
    "from src.diff_expression_model import get_model, get_siamese_model, post_hoc_conjoining, get_auroc\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we start from this data pickle as I'm not aware how Helder did DE analysis and generated the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath = \"/group/transreg/heopd/dlpipe/results/ath/aba/dlresults/predetermined_dataset/dataset_solid_chrome.pkl\"\n",
    "with open(ppath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'GeneFamily', 'seqs', 'ohs', 'rcohs', 'ohsDuo',\n",
       "       'in_original_balanced', 'set', 'npshap-single', 'npshap-posthoc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    1900\n",
       "valid     257\n",
       "test      241\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"set\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how to subdivide the dataset into train-test split we only take the following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.reset_index()\n",
    "dataset = dataset[[\"geneID\", \"Category\", \"GeneFamily\", \"seqs\"]]\n",
    "dataset.rename(columns={\"geneID\":\"GeneID\", \"Category\":\"Label\", \"seqs\": \"Sequence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...  \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...  \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...  \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...  \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...  \n",
       "...                                                 ...  \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...  \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...  \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...  \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...  \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...  \n",
       "\n",
       "[2398 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encode & reverse-complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import one_hot_encode_series, reverse_complement_series, reverse_complement_sequence\n",
    "dataset[\"One_hot_encoded\"] = one_hot_encode_series(dataset[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"RC_one_hot_encoded\"] = reverse_complement_series(dataset[\"One_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>One_hot_encoded</th>\n",
       "      <th>RC_one_hot_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "      <td>[[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \\\n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...   \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...   \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...   \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...   \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...   \n",
       "...                                                 ...   \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...   \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...   \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...   \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...   \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...   \n",
       "\n",
       "                                        One_hot_encoded  \\\n",
       "0     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "1     [[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...   \n",
       "2     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...   \n",
       "3     [[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...   \n",
       "4     [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...   \n",
       "...                                                 ...   \n",
       "2393  [[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "2394  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "2395  [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...   \n",
       "2396  [[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...   \n",
       "2397  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "\n",
       "                                     RC_one_hot_encoded  \n",
       "0     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "1     [[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2     [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "3     [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...  \n",
       "4     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...  \n",
       "...                                                 ...  \n",
       "2393  [[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...  \n",
       "2394  [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2395  [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "2396  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...  \n",
       "2397  [[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...  \n",
       "\n",
       "[2398 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import grouped_shuffle_split\n",
    "train_df, validation_test_df = grouped_shuffle_split(dataset, dataset[\"GeneFamily\"], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df, test_df  = grouped_shuffle_split(validation_test_df, validation_test_df[\"GeneFamily\"], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 1900\n",
      "Length of validation set: 257\n",
      "Length of test set: 241\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training set: {train_df.shape[0]}\")\n",
    "print(f\"Length of validation set: {validation_df.shape[0]}\")\n",
    "print(f\"Length of test set: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_and_labels(df):\n",
    "\tohe_np = np.stack(df[\"One_hot_encoded\"])\n",
    "\trc_np = np.stack(df[\"RC_one_hot_encoded\"])\n",
    "\n",
    "\tx = np.append(ohe_np, rc_np, axis=0)\n",
    "\tx = x.astype('float32')\n",
    "\ty = np.append(df[\"Label\"], df[\"Label\"])\n",
    "\treturn x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = get_input_and_labels(train_df)\n",
    "x_validation, y_validation = get_input_and_labels(validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model uses evo augmentation, a list of possible nucleotide operations needs to be given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 09:35:55.174789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/shared/apps/x86_64/dependencies_rl9:/software/shared/apps/x86_64/git/2.13.1/lib64/\n",
      "2024-07-08 09:35:55.174873: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-08 09:35:55.174946: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cyclone4.psblocal): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "augment_list = [\n",
    "    augment.RandomRC(rc_prob=0.5),\n",
    "    augment.RandomInsertionBatch(insert_min=0, insert_max=20),\n",
    "    augment.RandomDeletion(delete_min=0, delete_max=30),\n",
    "    augment.RandomTranslocationBatch(shift_min=0, shift_max=20),\n",
    "    augment.RandomMutation(mutate_frac=0.05),\n",
    "    augment.RandomNoise()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the shape of the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_df[\"One_hot_encoded\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(input_shape=input_shape, perform_evoaug=True, augment_list=augment_list,learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the hyperparameter parameters are set, we will do one more run with all possible training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full_train = np.append(x_train, x_validation, axis=0)\n",
    "y_full_train = np.append(y_train, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\tpatience=20,\n",
    "\t\t\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
    "# reduce learning rate callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tfactor=0.1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=1e-7,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tverbose=1)\n",
    "callbacks = [early_stopping_callback, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /shared/clssoft/apps/x86_64/regquest/1.0/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "38/38 [==============================] - 92s 1s/step - loss: 0.6940 - acc: 0.5045 - auROC: 0.5053 - auPRC: 0.4971 - true_positives: 1003.0000 - auroc: 0.5053 - val_loss: 0.6962 - val_acc: 0.4981 - val_auROC: 0.5586 - val_auPRC: 0.5428 - val_true_positives: 0.0000e+00 - val_auroc: 0.5586 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6937 - acc: 0.5118 - auROC: 0.5081 - auPRC: 0.5119 - true_positives: 563.0000 - auroc: 0.5081 - val_loss: 0.6933 - val_acc: 0.5019 - val_auROC: 0.5693 - val_auPRC: 0.5591 - val_true_positives: 258.0000 - val_auroc: 0.5693 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.6933 - acc: 0.5153 - auROC: 0.5131 - auPRC: 0.5111 - true_positives: 650.0000 - auroc: 0.5131 - val_loss: 0.6906 - val_acc: 0.5798 - val_auROC: 0.6273 - val_auPRC: 0.6405 - val_true_positives: 165.0000 - val_auroc: 0.6273 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6924 - acc: 0.5282 - auROC: 0.5304 - auPRC: 0.5142 - true_positives: 842.0000 - auroc: 0.5304 - val_loss: 0.6877 - val_acc: 0.5817 - val_auROC: 0.6317 - val_auPRC: 0.6020 - val_true_positives: 190.0000 - val_auroc: 0.6317 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6886 - acc: 0.5442 - auROC: 0.5551 - auPRC: 0.5323 - true_positives: 1067.0000 - auroc: 0.5551 - val_loss: 0.6809 - val_acc: 0.6012 - val_auROC: 0.6452 - val_auPRC: 0.6195 - val_true_positives: 173.0000 - val_auroc: 0.6452 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "38/38 [==============================] - 35s 948ms/step - loss: 0.6812 - acc: 0.5711 - auROC: 0.5895 - auPRC: 0.5569 - true_positives: 1128.0000 - auroc: 0.5895 - val_loss: 0.6714 - val_acc: 0.6187 - val_auROC: 0.6488 - val_auPRC: 0.6051 - val_true_positives: 186.0000 - val_auroc: 0.6488 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.6707 - acc: 0.5871 - auROC: 0.6162 - auPRC: 0.5740 - true_positives: 1176.0000 - auroc: 0.6162 - val_loss: 0.6737 - val_acc: 0.5681 - val_auROC: 0.6573 - val_auPRC: 0.6212 - val_true_positives: 232.0000 - val_auroc: 0.6573 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.6696 - acc: 0.5847 - auROC: 0.6152 - auPRC: 0.5830 - true_positives: 1268.0000 - auroc: 0.6152 - val_loss: 0.6802 - val_acc: 0.5525 - val_auROC: 0.6563 - val_auPRC: 0.6209 - val_true_positives: 241.0000 - val_auroc: 0.6563 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.6662 - acc: 0.5874 - auROC: 0.6270 - auPRC: 0.5892 - true_positives: 1175.0000 - auroc: 0.6270 - val_loss: 0.6559 - val_acc: 0.6167 - val_auROC: 0.6720 - val_auPRC: 0.6407 - val_true_positives: 148.0000 - val_auroc: 0.6720 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6676 - acc: 0.5900 - auROC: 0.6289 - auPRC: 0.5973 - true_positives: 1302.0000 - auroc: 0.6289 - val_loss: 0.6540 - val_acc: 0.6167 - val_auROC: 0.6698 - val_auPRC: 0.6233 - val_true_positives: 166.0000 - val_auroc: 0.6698 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.6667 - acc: 0.5926 - auROC: 0.6257 - auPRC: 0.5978 - true_positives: 1222.0000 - auroc: 0.6257 - val_loss: 0.6543 - val_acc: 0.6187 - val_auROC: 0.6773 - val_auPRC: 0.6382 - val_true_positives: 205.0000 - val_auroc: 0.6773 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6610 - acc: 0.6016 - auROC: 0.6405 - auPRC: 0.6057 - true_positives: 1296.0000 - auroc: 0.6405 - val_loss: 0.6836 - val_acc: 0.5467 - val_auROC: 0.6509 - val_auPRC: 0.6232 - val_true_positives: 244.0000 - val_auroc: 0.6509 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6516 - acc: 0.6242 - auROC: 0.6607 - auPRC: 0.6175 - true_positives: 1329.0000 - auroc: 0.6607 - val_loss: 0.6470 - val_acc: 0.6245 - val_auROC: 0.6768 - val_auPRC: 0.6438 - val_true_positives: 171.0000 - val_auroc: 0.6768 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "38/38 [==============================] - 40s 973ms/step - loss: 0.6380 - acc: 0.6350 - auROC: 0.6815 - auPRC: 0.6384 - true_positives: 1284.0000 - auroc: 0.6815 - val_loss: 0.6446 - val_acc: 0.6265 - val_auROC: 0.6852 - val_auPRC: 0.6498 - val_true_positives: 199.0000 - val_auroc: 0.6852 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "38/38 [==============================] - 37s 976ms/step - loss: 0.6386 - acc: 0.6347 - auROC: 0.6828 - auPRC: 0.6428 - true_positives: 1299.0000 - auroc: 0.6828 - val_loss: 0.6388 - val_acc: 0.6401 - val_auROC: 0.6982 - val_auPRC: 0.6766 - val_true_positives: 205.0000 - val_auroc: 0.6982 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "38/38 [==============================] - 48s 1s/step - loss: 0.6345 - acc: 0.6445 - auROC: 0.6901 - auPRC: 0.6492 - true_positives: 1400.0000 - auroc: 0.6901 - val_loss: 0.6442 - val_acc: 0.6187 - val_auROC: 0.6947 - val_auPRC: 0.6743 - val_true_positives: 204.0000 - val_auroc: 0.6947 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.6325 - acc: 0.6474 - auROC: 0.6943 - auPRC: 0.6567 - true_positives: 1292.0000 - auroc: 0.6943 - val_loss: 0.6561 - val_acc: 0.6109 - val_auROC: 0.6885 - val_auPRC: 0.6813 - val_true_positives: 223.0000 - val_auroc: 0.6885 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6366 - acc: 0.6424 - auROC: 0.6847 - auPRC: 0.6347 - true_positives: 1332.0000 - auroc: 0.6847 - val_loss: 0.6438 - val_acc: 0.6206 - val_auROC: 0.6962 - val_auPRC: 0.6901 - val_true_positives: 216.0000 - val_auroc: 0.6962 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "38/38 [==============================] - 19s 492ms/step - loss: 0.6199 - acc: 0.6629 - auROC: 0.7149 - auPRC: 0.6739 - true_positives: 1345.0000 - auroc: 0.7149 - val_loss: 0.6437 - val_acc: 0.6206 - val_auROC: 0.7006 - val_auPRC: 0.6925 - val_true_positives: 217.0000 - val_auroc: 0.7006 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.6232 - acc: 0.6513 - auROC: 0.7035 - auPRC: 0.6679 - true_positives: 1371.0000 - auroc: 0.7035 - val_loss: 0.6332 - val_acc: 0.6420 - val_auROC: 0.7129 - val_auPRC: 0.7115 - val_true_positives: 145.0000 - val_auroc: 0.7129 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.6053 - acc: 0.6708 - auROC: 0.7299 - auPRC: 0.6863 - true_positives: 1366.0000 - auroc: 0.7299 - val_loss: 0.6253 - val_acc: 0.6381 - val_auROC: 0.7137 - val_auPRC: 0.7085 - val_true_positives: 167.0000 - val_auroc: 0.7137 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "38/38 [==============================] - 36s 959ms/step - loss: 0.6107 - acc: 0.6629 - auROC: 0.7221 - auPRC: 0.6905 - true_positives: 1360.0000 - auroc: 0.7221 - val_loss: 0.6248 - val_acc: 0.6342 - val_auROC: 0.7117 - val_auPRC: 0.7047 - val_true_positives: 182.0000 - val_auroc: 0.7117 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6016 - acc: 0.6811 - auROC: 0.7348 - auPRC: 0.6968 - true_positives: 1394.0000 - auroc: 0.7348 - val_loss: 0.6253 - val_acc: 0.6420 - val_auROC: 0.7091 - val_auPRC: 0.7108 - val_true_positives: 165.0000 - val_auroc: 0.7091 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5948 - acc: 0.6863 - auROC: 0.7435 - auPRC: 0.7130 - true_positives: 1375.0000 - auroc: 0.7435 - val_loss: 0.6268 - val_acc: 0.6265 - val_auROC: 0.7049 - val_auPRC: 0.7058 - val_true_positives: 200.0000 - val_auroc: 0.7049 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.6030 - acc: 0.6800 - auROC: 0.7390 - auPRC: 0.7127 - true_positives: 1402.0000 - auroc: 0.7390 - val_loss: 0.6197 - val_acc: 0.6381 - val_auROC: 0.7150 - val_auPRC: 0.7140 - val_true_positives: 171.0000 - val_auroc: 0.7150 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5923 - acc: 0.6824 - auROC: 0.7474 - auPRC: 0.7210 - true_positives: 1309.0000 - auroc: 0.7474 - val_loss: 0.6361 - val_acc: 0.6245 - val_auROC: 0.7087 - val_auPRC: 0.7070 - val_true_positives: 222.0000 - val_auroc: 0.7087 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "38/38 [==============================] - 34s 909ms/step - loss: 0.5923 - acc: 0.6855 - auROC: 0.7506 - auPRC: 0.7301 - true_positives: 1403.0000 - auroc: 0.7506 - val_loss: 0.6187 - val_acc: 0.6459 - val_auROC: 0.7180 - val_auPRC: 0.7154 - val_true_positives: 166.0000 - val_auroc: 0.7180 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5860 - acc: 0.6905 - auROC: 0.7550 - auPRC: 0.7329 - true_positives: 1308.0000 - auroc: 0.7550 - val_loss: 0.6094 - val_acc: 0.6732 - val_auROC: 0.7334 - val_auPRC: 0.7339 - val_true_positives: 160.0000 - val_auroc: 0.7334 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5827 - acc: 0.6889 - auROC: 0.7575 - auPRC: 0.7364 - true_positives: 1369.0000 - auroc: 0.7575 - val_loss: 0.6305 - val_acc: 0.6265 - val_auROC: 0.7059 - val_auPRC: 0.7099 - val_true_positives: 223.0000 - val_auroc: 0.7059 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5858 - acc: 0.6821 - auROC: 0.7542 - auPRC: 0.7425 - true_positives: 1361.0000 - auroc: 0.7542 - val_loss: 0.6157 - val_acc: 0.6245 - val_auROC: 0.7127 - val_auPRC: 0.7139 - val_true_positives: 184.0000 - val_auroc: 0.7127 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5794 - acc: 0.6934 - auROC: 0.7597 - auPRC: 0.7397 - true_positives: 1341.0000 - auroc: 0.7597 - val_loss: 0.6045 - val_acc: 0.6770 - val_auROC: 0.7362 - val_auPRC: 0.7324 - val_true_positives: 173.0000 - val_auroc: 0.7362 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5723 - acc: 0.7005 - auROC: 0.7684 - auPRC: 0.7437 - true_positives: 1413.0000 - auroc: 0.7684 - val_loss: 0.6025 - val_acc: 0.6595 - val_auROC: 0.7357 - val_auPRC: 0.7308 - val_true_positives: 199.0000 - val_auroc: 0.7357 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5772 - acc: 0.6892 - auROC: 0.7609 - auPRC: 0.7442 - true_positives: 1374.0000 - auroc: 0.7609 - val_loss: 0.6105 - val_acc: 0.6576 - val_auROC: 0.7302 - val_auPRC: 0.7233 - val_true_positives: 165.0000 - val_auroc: 0.7302 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5930 - acc: 0.6853 - auROC: 0.7489 - auPRC: 0.7287 - true_positives: 1326.0000 - auroc: 0.7489 - val_loss: 0.6332 - val_acc: 0.6265 - val_auROC: 0.7042 - val_auPRC: 0.7075 - val_true_positives: 221.0000 - val_auroc: 0.7042 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5917 - acc: 0.6742 - auROC: 0.7475 - auPRC: 0.7460 - true_positives: 1334.0000 - auroc: 0.7475 - val_loss: 0.6183 - val_acc: 0.6556 - val_auROC: 0.7242 - val_auPRC: 0.7223 - val_true_positives: 209.0000 - val_auroc: 0.7242 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5697 - acc: 0.6947 - auROC: 0.7718 - auPRC: 0.7523 - true_positives: 1329.0000 - auroc: 0.7718 - val_loss: 0.6019 - val_acc: 0.6848 - val_auROC: 0.7466 - val_auPRC: 0.7453 - val_true_positives: 172.0000 - val_auroc: 0.7466 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5730 - acc: 0.6929 - auROC: 0.7665 - auPRC: 0.7536 - true_positives: 1365.0000 - auroc: 0.7665 - val_loss: 0.5996 - val_acc: 0.6537 - val_auROC: 0.7396 - val_auPRC: 0.7408 - val_true_positives: 160.0000 - val_auroc: 0.7396 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5683 - acc: 0.7058 - auROC: 0.7745 - auPRC: 0.7615 - true_positives: 1386.0000 - auroc: 0.7745 - val_loss: 0.5973 - val_acc: 0.6576 - val_auROC: 0.7396 - val_auPRC: 0.7447 - val_true_positives: 199.0000 - val_auroc: 0.7396 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.5580 - acc: 0.7134 - auROC: 0.7845 - auPRC: 0.7653 - true_positives: 1372.0000 - auroc: 0.7845 - val_loss: 0.5952 - val_acc: 0.6965 - val_auROC: 0.7438 - val_auPRC: 0.7483 - val_true_positives: 187.0000 - val_auroc: 0.7438 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5640 - acc: 0.7050 - auROC: 0.7751 - auPRC: 0.7615 - true_positives: 1375.0000 - auroc: 0.7751 - val_loss: 0.6075 - val_acc: 0.6556 - val_auROC: 0.7303 - val_auPRC: 0.7263 - val_true_positives: 214.0000 - val_auroc: 0.7303 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5715 - acc: 0.6984 - auROC: 0.7698 - auPRC: 0.7622 - true_positives: 1383.0000 - auroc: 0.7698 - val_loss: 0.6192 - val_acc: 0.6381 - val_auROC: 0.7170 - val_auPRC: 0.7232 - val_true_positives: 214.0000 - val_auroc: 0.7170 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.5407 - acc: 0.7261 - auROC: 0.7995 - auPRC: 0.7830 - true_positives: 1390.0000 - auroc: 0.7995 - val_loss: 0.5994 - val_acc: 0.6809 - val_auROC: 0.7536 - val_auPRC: 0.7536 - val_true_positives: 161.0000 - val_auroc: 0.7536 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5570 - acc: 0.7118 - auROC: 0.7855 - auPRC: 0.7678 - true_positives: 1398.0000 - auroc: 0.7855 - val_loss: 0.6104 - val_acc: 0.6595 - val_auROC: 0.7277 - val_auPRC: 0.7262 - val_true_positives: 213.0000 - val_auroc: 0.7277 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5630 - acc: 0.7137 - auROC: 0.7805 - auPRC: 0.7572 - true_positives: 1420.0000 - auroc: 0.7805\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5630 - acc: 0.7137 - auROC: 0.7805 - auPRC: 0.7572 - true_positives: 1420.0000 - auroc: 0.7805 - val_loss: 0.6022 - val_acc: 0.6770 - val_auROC: 0.7356 - val_auPRC: 0.7377 - val_true_positives: 177.0000 - val_auroc: 0.7356 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "38/38 [==============================] - 46s 1s/step - loss: 0.5378 - acc: 0.7366 - auROC: 0.8031 - auPRC: 0.7869 - true_positives: 1408.0000 - auroc: 0.8031 - val_loss: 0.6021 - val_acc: 0.6732 - val_auROC: 0.7330 - val_auPRC: 0.7371 - val_true_positives: 187.0000 - val_auroc: 0.7330 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5362 - acc: 0.7203 - auROC: 0.8026 - auPRC: 0.7906 - true_positives: 1388.0000 - auroc: 0.8026 - val_loss: 0.6004 - val_acc: 0.6732 - val_auROC: 0.7362 - val_auPRC: 0.7371 - val_true_positives: 191.0000 - val_auroc: 0.7362 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5420 - acc: 0.7189 - auROC: 0.7978 - auPRC: 0.7926 - true_positives: 1387.0000 - auroc: 0.7978 - val_loss: 0.6020 - val_acc: 0.6654 - val_auROC: 0.7355 - val_auPRC: 0.7376 - val_true_positives: 185.0000 - val_auroc: 0.7355 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.5449 - acc: 0.7250 - auROC: 0.7963 - auPRC: 0.7847 - true_positives: 1412.0000 - auroc: 0.7963 - val_loss: 0.6005 - val_acc: 0.6556 - val_auROC: 0.7354 - val_auPRC: 0.7371 - val_true_positives: 178.0000 - val_auroc: 0.7354 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5383 - acc: 0.7289 - auROC: 0.8019 - auPRC: 0.7885 - true_positives: 1403.0000 - auroc: 0.8019\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5383 - acc: 0.7289 - auROC: 0.8019 - auPRC: 0.7885 - true_positives: 1403.0000 - auroc: 0.8019 - val_loss: 0.6034 - val_acc: 0.6595 - val_auROC: 0.7319 - val_auPRC: 0.7331 - val_true_positives: 191.0000 - val_auroc: 0.7319 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5420 - acc: 0.7234 - auROC: 0.7984 - auPRC: 0.7865 - true_positives: 1407.0000 - auroc: 0.7984 - val_loss: 0.6053 - val_acc: 0.6595 - val_auROC: 0.7303 - val_auPRC: 0.7335 - val_true_positives: 188.0000 - val_auroc: 0.7303 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5332 - acc: 0.7361 - auROC: 0.8081 - auPRC: 0.7929 - true_positives: 1422.0000 - auroc: 0.8081 - val_loss: 0.5991 - val_acc: 0.6654 - val_auROC: 0.7352 - val_auPRC: 0.7376 - val_true_positives: 191.0000 - val_auroc: 0.7352 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5355 - acc: 0.7287 - auROC: 0.8052 - auPRC: 0.7973 - true_positives: 1397.0000 - auroc: 0.8052 - val_loss: 0.6039 - val_acc: 0.6693 - val_auROC: 0.7298 - val_auPRC: 0.7292 - val_true_positives: 195.0000 - val_auroc: 0.7298 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5383 - acc: 0.7339 - auROC: 0.8026 - auPRC: 0.7898 - true_positives: 1444.0000 - auroc: 0.8026 - val_loss: 0.6050 - val_acc: 0.6615 - val_auROC: 0.7286 - val_auPRC: 0.7311 - val_true_positives: 189.0000 - val_auroc: 0.7286 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5356 - acc: 0.7332 - auROC: 0.8058 - auPRC: 0.7925 - true_positives: 1414.0000 - auroc: 0.8058\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5356 - acc: 0.7332 - auROC: 0.8058 - auPRC: 0.7925 - true_positives: 1414.0000 - auroc: 0.8058 - val_loss: 0.6027 - val_acc: 0.6615 - val_auROC: 0.7324 - val_auPRC: 0.7362 - val_true_positives: 193.0000 - val_auroc: 0.7324 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5378 - acc: 0.7213 - auROC: 0.8002 - auPRC: 0.7933 - true_positives: 1405.0000 - auroc: 0.8002 - val_loss: 0.6031 - val_acc: 0.6673 - val_auROC: 0.7308 - val_auPRC: 0.7338 - val_true_positives: 192.0000 - val_auroc: 0.7308 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5329 - acc: 0.7292 - auROC: 0.8063 - auPRC: 0.7941 - true_positives: 1398.0000 - auroc: 0.8063 - val_loss: 0.6009 - val_acc: 0.6595 - val_auROC: 0.7334 - val_auPRC: 0.7362 - val_true_positives: 188.0000 - val_auroc: 0.7334 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5292 - acc: 0.7361 - auROC: 0.8112 - auPRC: 0.7997 - true_positives: 1420.0000 - auroc: 0.8112 - val_loss: 0.6055 - val_acc: 0.6498 - val_auROC: 0.7283 - val_auPRC: 0.7324 - val_true_positives: 187.0000 - val_auroc: 0.7283 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5414 - acc: 0.7150 - auROC: 0.7974 - auPRC: 0.7931 - true_positives: 1378.0000 - auroc: 0.7974 - val_loss: 0.6019 - val_acc: 0.6654 - val_auROC: 0.7319 - val_auPRC: 0.7332 - val_true_positives: 191.0000 - val_auroc: 0.7319 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "38/38 [==============================] - ETA: 0s - loss: 0.5352 - acc: 0.7326 - auROC: 0.8047 - auPRC: 0.7933 - true_positives: 1432.0000 - auroc: 0.8047Restoring model weights from the end of the best epoch: 39.\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5352 - acc: 0.7326 - auROC: 0.8047 - auPRC: 0.7933 - true_positives: 1432.0000 - auroc: 0.8047 - val_loss: 0.6038 - val_acc: 0.6693 - val_auROC: 0.7303 - val_auPRC: 0.7312 - val_true_positives: 193.0000 - val_auroc: 0.7303 - lr: 1.0000e-06\n",
      "Epoch 59: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,\n",
    "\t\t\t\t\ty_train,\n",
    "\t\t\t\t\tepochs=100,\n",
    "\t\t\t\t\tbatch_size=100,\n",
    "\t\t\t\t\tvalidation_data=(x_validation, y_validation),\n",
    "\t\t\t\t\tcallbacks=callbacks\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952149033546448"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8164934164934164"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model = get_siamese_model(model.model)\n",
    "\n",
    "x_test = np.stack(test_df[\"One_hot_encoded\"])\n",
    "x_test_rc = np.stack(test_df[\"RC_one_hot_encoded\"])\n",
    "\n",
    "y_test = test_df[\"Label\"].to_numpy()\n",
    "\n",
    "x_test = model._pad_end(x_test)\n",
    "x_test_rc = model._pad_end(x_test_rc)\n",
    "\n",
    "predictions_categories, predictions = post_hoc_conjoining(siamese_model, x_test, x_test_rc)\n",
    "\n",
    "get_auroc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune evo aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5584 - acc: 0.7108 - auROC: 0.7895 - auPRC: 0.7737 - true_positives: 1240.0000 - auroc: 0.7895 - val_loss: 0.5943 - val_acc: 0.6829 - val_auROC: 0.7452 - val_auPRC: 0.7493 - val_true_positives: 186.0000 - val_auroc: 0.7452\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5700 - acc: 0.6992 - auROC: 0.7770 - auPRC: 0.7706 - true_positives: 1219.0000 - auroc: 0.7770 - val_loss: 0.5947 - val_acc: 0.6868 - val_auROC: 0.7450 - val_auPRC: 0.7507 - val_true_positives: 184.0000 - val_auroc: 0.7450\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5627 - acc: 0.7071 - auROC: 0.7826 - auPRC: 0.7680 - true_positives: 1242.0000 - auroc: 0.7826 - val_loss: 0.5963 - val_acc: 0.6887 - val_auROC: 0.7417 - val_auPRC: 0.7482 - val_true_positives: 188.0000 - val_auroc: 0.7417\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5567 - acc: 0.7042 - auROC: 0.7878 - auPRC: 0.7742 - true_positives: 1229.0000 - auroc: 0.7878 - val_loss: 0.5937 - val_acc: 0.6887 - val_auROC: 0.7453 - val_auPRC: 0.7499 - val_true_positives: 185.0000 - val_auroc: 0.7453\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5532 - acc: 0.7116 - auROC: 0.7930 - auPRC: 0.7829 - true_positives: 1263.0000 - auroc: 0.7930 - val_loss: 0.5955 - val_acc: 0.6790 - val_auROC: 0.7442 - val_auPRC: 0.7503 - val_true_positives: 180.0000 - val_auroc: 0.7442\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5545 - acc: 0.7147 - auROC: 0.7909 - auPRC: 0.7744 - true_positives: 1267.0000 - auroc: 0.7909 - val_loss: 0.5956 - val_acc: 0.6868 - val_auROC: 0.7422 - val_auPRC: 0.7481 - val_true_positives: 186.0000 - val_auroc: 0.7422\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5612 - acc: 0.7076 - auROC: 0.7842 - auPRC: 0.7749 - true_positives: 1256.0000 - auroc: 0.7842 - val_loss: 0.5973 - val_acc: 0.6790 - val_auROC: 0.7409 - val_auPRC: 0.7445 - val_true_positives: 180.0000 - val_auroc: 0.7409\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5543 - acc: 0.7179 - auROC: 0.7911 - auPRC: 0.7754 - true_positives: 1297.0000 - auroc: 0.7911 - val_loss: 0.5957 - val_acc: 0.6809 - val_auROC: 0.7423 - val_auPRC: 0.7471 - val_true_positives: 184.0000 - val_auroc: 0.7423\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5468 - acc: 0.7182 - auROC: 0.7959 - auPRC: 0.7845 - true_positives: 1308.0000 - auroc: 0.7959 - val_loss: 0.5948 - val_acc: 0.6770 - val_auROC: 0.7440 - val_auPRC: 0.7494 - val_true_positives: 184.0000 - val_auroc: 0.7440\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5603 - acc: 0.7105 - auROC: 0.7847 - auPRC: 0.7692 - true_positives: 1256.0000 - auroc: 0.7847 - val_loss: 0.5959 - val_acc: 0.6829 - val_auROC: 0.7421 - val_auPRC: 0.7458 - val_true_positives: 187.0000 - val_auroc: 0.7421\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 44s 1s/step - loss: 0.5541 - acc: 0.7163 - auROC: 0.7909 - auPRC: 0.7730 - true_positives: 1301.0000 - auroc: 0.7909 - val_loss: 0.5952 - val_acc: 0.6887 - val_auROC: 0.7438 - val_auPRC: 0.7482 - val_true_positives: 185.0000 - val_auroc: 0.7438\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 39s 1s/step - loss: 0.5664 - acc: 0.7068 - auROC: 0.7805 - auPRC: 0.7635 - true_positives: 1268.0000 - auroc: 0.7805 - val_loss: 0.5950 - val_acc: 0.6907 - val_auROC: 0.7437 - val_auPRC: 0.7471 - val_true_positives: 188.0000 - val_auroc: 0.7437\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5565 - acc: 0.7118 - auROC: 0.7882 - auPRC: 0.7737 - true_positives: 1277.0000 - auroc: 0.7882 - val_loss: 0.5924 - val_acc: 0.6907 - val_auROC: 0.7465 - val_auPRC: 0.7508 - val_true_positives: 188.0000 - val_auroc: 0.7465\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 45s 1s/step - loss: 0.5519 - acc: 0.7145 - auROC: 0.7919 - auPRC: 0.7786 - true_positives: 1277.0000 - auroc: 0.7919 - val_loss: 0.5940 - val_acc: 0.6809 - val_auROC: 0.7460 - val_auPRC: 0.7544 - val_true_positives: 185.0000 - val_auroc: 0.7460\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 41s 1s/step - loss: 0.5563 - acc: 0.7087 - auROC: 0.7867 - auPRC: 0.7801 - true_positives: 1273.0000 - auroc: 0.7867 - val_loss: 0.5920 - val_acc: 0.6965 - val_auROC: 0.7476 - val_auPRC: 0.7530 - val_true_positives: 192.0000 - val_auroc: 0.7476\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.5461 - acc: 0.7263 - auROC: 0.7993 - auPRC: 0.7850 - true_positives: 1324.0000 - auroc: 0.7993 - val_loss: 0.5927 - val_acc: 0.6887 - val_auROC: 0.7447 - val_auPRC: 0.7510 - val_true_positives: 190.0000 - val_auroc: 0.7447\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 43s 1s/step - loss: 0.5558 - acc: 0.7092 - auROC: 0.7889 - auPRC: 0.7757 - true_positives: 1264.0000 - auroc: 0.7889 - val_loss: 0.5942 - val_acc: 0.6829 - val_auROC: 0.7456 - val_auPRC: 0.7515 - val_true_positives: 188.0000 - val_auroc: 0.7456\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 34s 903ms/step - loss: 0.5499 - acc: 0.7121 - auROC: 0.7929 - auPRC: 0.7803 - true_positives: 1287.0000 - auroc: 0.7929 - val_loss: 0.5977 - val_acc: 0.6770 - val_auROC: 0.7386 - val_auPRC: 0.7455 - val_true_positives: 186.0000 - val_auroc: 0.7386\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5521 - acc: 0.7216 - auROC: 0.7949 - auPRC: 0.7859 - true_positives: 1314.0000 - auroc: 0.7949 - val_loss: 0.5942 - val_acc: 0.6965 - val_auROC: 0.7441 - val_auPRC: 0.7496 - val_true_positives: 194.0000 - val_auroc: 0.7441\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 42s 1s/step - loss: 0.5593 - acc: 0.7042 - auROC: 0.7877 - auPRC: 0.7780 - true_positives: 1252.0000 - auroc: 0.7877 - val_loss: 0.5959 - val_acc: 0.6751 - val_auROC: 0.7424 - val_auPRC: 0.7488 - val_true_positives: 186.0000 - val_auroc: 0.7424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa30d447b20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "# set up fine-tuning\n",
    "finetune_optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.finetune_mode(optimizer=finetune_optimizer)\n",
    "\n",
    "\n",
    "# set up callbacks\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\tpatience=10,\n",
    "\t\t\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
    "# train model\n",
    "model.fit(x_train, y_train,\n",
    "                epochs=20,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_validation, y_validation),\n",
    "                callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform post-hoc conjoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = get_siamese_model(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.stack(test_df[\"One_hot_encoded\"])\n",
    "x_test_rc = np.stack(test_df[\"RC_one_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[\"Label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used evo aug in our model all the sequences which were trained on, were of length 620. We use the evoaug padding function to pad the test set to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = model._pad_end(x_test)\n",
    "x_test_rc = model._pad_end(x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 623ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_categories, predictions = post_hoc_conjoining(siamese_model, x_test, x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8167013167013167"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auroc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.74      0.72       111\n",
      "           1       0.77      0.74      0.75       130\n",
      "\n",
      "    accuracy                           0.74       241\n",
      "   macro avg       0.74      0.74      0.74       241\n",
      "weighted avg       0.74      0.74      0.74       241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions_categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
