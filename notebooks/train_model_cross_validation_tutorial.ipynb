{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "/storage/nas6/group/biocomp/projects/transreg/sathi/DeepDifE\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd /group/transreg/sathi/DeepDifE \n",
    "\n",
    "import pickle\n",
    "import importlib\n",
    "import esparto\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evoaug_tf import evoaug, augment\n",
    "from src.diff_expression_model import get_model, get_siamese_model, post_hoc_conjoining, get_auroc\n",
    "from skopt.utils import use_named_args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we start from this data pickle as I'm not aware how Helder did DE analysis and generated the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppath = \"/group/transreg/heopd/dlpipe/results/ath/aba/dlresults/predetermined_dataset/dataset_solid_chrome.pkl\"\n",
    "with open(ppath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Category', 'GeneFamily', 'seqs', 'ohs', 'rcohs', 'ohsDuo',\n",
       "       'in_original_balanced', 'set', 'npshap-single', 'npshap-posthoc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    1900\n",
       "valid     257\n",
       "test      241\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"set\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show how to subdivide the dataset into train-test split we only take the following columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.reset_index()\n",
    "dataset = dataset[[\"geneID\", \"Category\", \"GeneFamily\", \"seqs\"]]\n",
    "dataset.rename(columns={\"geneID\":\"GeneID\", \"Category\":\"Label\", \"seqs\": \"Sequence\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...  \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...  \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...  \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...  \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...  \n",
       "...                                                 ...  \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...  \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...  \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...  \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...  \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...  \n",
       "\n",
       "[2398 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot-encode & reverse-complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import one_hot_encode_series, reverse_complement_series, reverse_complement_sequence\n",
    "dataset[\"One_hot_encoded\"] = one_hot_encode_series(dataset[\"Sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"RC_one_hot_encoded\"] = reverse_complement_series(dataset[\"One_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Label</th>\n",
       "      <th>GeneFamily</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>One_hot_encoded</th>\n",
       "      <th>RC_one_hot_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT4G27120</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000881</td>\n",
       "      <td>TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT4G19600</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000740</td>\n",
       "      <td>GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT3G60880</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D003119</td>\n",
       "      <td>AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT5G06960</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000319</td>\n",
       "      <td>CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...</td>\n",
       "      <td>[[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT1G14890</td>\n",
       "      <td>0</td>\n",
       "      <td>HOM04D000273</td>\n",
       "      <td>TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>AT5G64230</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D003278</td>\n",
       "      <td>AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...</td>\n",
       "      <td>[[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...</td>\n",
       "      <td>[[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>AT5G64780</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D002552</td>\n",
       "      <td>TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>AT4G30470</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000082</td>\n",
       "      <td>TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...</td>\n",
       "      <td>[[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>AT3G51895</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D000270</td>\n",
       "      <td>TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>AT2G35585</td>\n",
       "      <td>1</td>\n",
       "      <td>HOM04D004118</td>\n",
       "      <td>TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...</td>\n",
       "      <td>[[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...</td>\n",
       "      <td>[[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2398 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         GeneID Label    GeneFamily  \\\n",
       "0     AT4G27120     0  HOM04D000881   \n",
       "1     AT4G19600     0  HOM04D000740   \n",
       "2     AT3G60880     0  HOM04D003119   \n",
       "3     AT5G06960     0  HOM04D000319   \n",
       "4     AT1G14890     0  HOM04D000273   \n",
       "...         ...   ...           ...   \n",
       "2393  AT5G64230     1  HOM04D003278   \n",
       "2394  AT5G64780     1  HOM04D002552   \n",
       "2395  AT4G30470     1  HOM04D000082   \n",
       "2396  AT3G51895     1  HOM04D000270   \n",
       "2397  AT2G35585     1  HOM04D004118   \n",
       "\n",
       "                                               Sequence  \\\n",
       "0     TAGAGAAGACAAGCGGTTATTTCGTAATTTCCCAGCGACTTTGAAA...   \n",
       "1     GTCAAGTAGTGAAATCAAGGTGTGAAGTAAGCTGAGGACAGATAAT...   \n",
       "2     AGTTGATATTGAATGAAATCTTCATGTTTTTTGATAAATGATTATA...   \n",
       "3     CACTTGTCAGATTCTTCTTACCAAATCCATCAACAAATAAGCAAAT...   \n",
       "4     TTGATATAACAGATTCAACACTAAAAATGAGTAAAATCTAAAAAAG...   \n",
       "...                                                 ...   \n",
       "2393  AAGAAAGAAAAACCGTACATAAACACCCATCTGGTATACCATCGTC...   \n",
       "2394  TTTTAGAAAGAAGAAGAAGGATTATTGCCTTATTGGTGAAGGGAAG...   \n",
       "2395  TATGTACAGTCTCTACATTTTTTCAAATACATTTTTTTCTTTTTCA...   \n",
       "2396  TGGTAAATAATTAAATATATAAGAACATTATTCTAAAGCGTTGAAT...   \n",
       "2397  TTTTGCCACTGCTGGCTCTGATGGTGCTTTCAATTTCTAGGACAAG...   \n",
       "\n",
       "                                        One_hot_encoded  \\\n",
       "0     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "1     [[0, 0, 1, 0], [0, 0, 0, 1], [0, 1, 0, 0], [1,...   \n",
       "2     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...   \n",
       "3     [[0, 1, 0, 0], [1, 0, 0, 0], [0, 1, 0, 0], [0,...   \n",
       "4     [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...   \n",
       "...                                                 ...   \n",
       "2393  [[1, 0, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0], [1,...   \n",
       "2394  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "2395  [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [0,...   \n",
       "2396  [[0, 0, 0, 1], [0, 0, 1, 0], [0, 0, 1, 0], [0,...   \n",
       "2397  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 0, 1], [0,...   \n",
       "\n",
       "                                     RC_one_hot_encoded  \n",
       "0     [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "1     [[0, 0, 1, 0], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2     [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "3     [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [1,...  \n",
       "4     [[0, 0, 0, 1], [1, 0, 0, 0], [0, 0, 0, 1], [1,...  \n",
       "...                                                 ...  \n",
       "2393  [[0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1], [0,...  \n",
       "2394  [[0, 0, 0, 1], [0, 0, 1, 0], [1, 0, 0, 0], [0,...  \n",
       "2395  [[1, 0, 0, 0], [0, 0, 1, 0], [0, 0, 1, 0], [0,...  \n",
       "2396  [[0, 0, 0, 1], [0, 0, 0, 1], [0, 0, 1, 0], [1,...  \n",
       "2397  [[0, 0, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0,...  \n",
       "\n",
       "[2398 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.prepare_dataset import grouped_shuffle_split\n",
    "train_df, test_df = grouped_shuffle_split(dataset, dataset[\"GeneFamily\"], 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 1900\n",
      "Length of test set: 498\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of training set: {train_df.shape[0]}\")\n",
    "print(f\"Length of test set: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first initialize the object that are static throughout the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-09 12:57:05.056212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /software/shared/apps/x86_64/dependencies_rl9:/software/shared/apps/x86_64/git/2.13.1/lib64/\n",
      "2024-07-09 12:57:05.056294: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-09 12:57:05.056369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cyclone4.psblocal): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "augment_list = [\n",
    "    augment.RandomRC(rc_prob=0.5),\n",
    "    augment.RandomInsertionBatch(insert_min=0, insert_max=20),\n",
    "    augment.RandomDeletion(delete_min=0, delete_max=30),\n",
    "    augment.RandomTranslocationBatch(shift_min=0, shift_max=20),\n",
    "    augment.RandomMutation(mutate_frac=0.05),\n",
    "    augment.RandomNoise()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping callback\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\tpatience=20,\n",
    "\t\t\t\t\t\t\t\t\t\t\tverbose=1,\n",
    "\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\trestore_best_weights=True)\n",
    "# reduce learning rate callback\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tfactor=0.1,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tpatience=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmin_lr=1e-7,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tmode='min',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tverbose=1)\n",
    "callbacks = [early_stopping_callback, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_df[\"One_hot_encoded\"].iloc[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_and_labels(df):\n",
    "\tohe_np = np.stack(df[\"One_hot_encoded\"])\n",
    "\trc_np = np.stack(df[\"RC_one_hot_encoded\"])\n",
    "\n",
    "\tx = np.append(ohe_np, rc_np, axis=0)\n",
    "\tx = x.astype('float32')\n",
    "\ty = np.append(df[\"Label\"], df[\"Label\"])\n",
    "\treturn x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_input_and_labels(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create the groups. Because we are using both forward and reverse complement we have to concat them with itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.concat([train_df[\"GeneFamily\"], train_df[\"GeneFamily\"]], axis = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 26s 446ms/step - loss: 0.6955 - acc: 0.4875 - auROC: 0.4793 - auPRC: 0.4706 - true_positives_18: 657.0000 - val_loss: 0.6938 - val_acc: 0.4987 - val_auROC: 0.5060 - val_auPRC: 0.5235 - val_true_positives_18: 1.0000 - lr: 0.0010\n",
      "Score for fold 0: Loss of 0.6937711238861084; accuracy of 0.4973684251308441; auroc of 0.505862295627594; auprc of 0.5241748094558716; TP of 0.0\n",
      "31/31 [==============================] - 26s 424ms/step - loss: 0.6947 - acc: 0.5010 - auROC: 0.4933 - auPRC: 0.4809 - true_positives_19: 321.0000 - val_loss: 0.6935 - val_acc: 0.4882 - val_auROC: 0.5405 - val_auPRC: 0.5534 - val_true_positives_19: 22.0000 - lr: 0.0010\n",
      "Score for fold 1: Loss of 0.6934657692909241; accuracy of 0.4973684251308441; auroc of 0.5365015864372253; auprc of 0.5551764965057373; TP of 27.0\n",
      "31/31 [==============================] - 27s 439ms/step - loss: 0.6960 - acc: 0.4809 - auROC: 0.4775 - auPRC: 0.4794 - true_positives_20: 876.0000 - val_loss: 0.6934 - val_acc: 0.5184 - val_auROC: 0.5015 - val_auPRC: 0.5026 - val_true_positives_20: 277.0000 - lr: 0.0010\n",
      "Score for fold 2: Loss of 0.6933785676956177; accuracy of 0.5157894492149353; auroc of 0.5075069069862366; auprc of 0.5071339011192322; TP of 278.0\n",
      "31/31 [==============================] - 22s 439ms/step - loss: 0.6946 - acc: 0.5003 - auROC: 0.5036 - auPRC: 0.4964 - true_positives_21: 849.0000 - val_loss: 0.6982 - val_acc: 0.4921 - val_auROC: 0.5873 - val_auPRC: 0.5703 - val_true_positives_21: 0.0000e+00 - lr: 0.0010\n",
      "Score for fold 3: Loss of 0.6981106996536255; accuracy of 0.49210527539253235; auroc of 0.5970429182052612; auprc of 0.5717699527740479; TP of 0.0\n",
      "31/31 [==============================] - 26s 448ms/step - loss: 0.6937 - acc: 0.5132 - auROC: 0.5096 - auPRC: 0.5139 - true_positives_22: 1155.0000 - val_loss: 0.6885 - val_acc: 0.5605 - val_auROC: 0.5187 - val_auPRC: 0.4702 - val_true_positives_22: 0.0000e+00 - lr: 0.0010\n",
      "Score for fold 4: Loss of 0.6884648203849792; accuracy of 0.5605263113975525; auroc of 0.5289491415023804; auprc of 0.4773809313774109; TP of 0.0\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 0: Loss of 0.6937711238861084; accuracy of 0.4973684251308441; AUROC of 0.505862295627594; AUPRC of 0.5241748094558716; TP of 0.0\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 1: Loss of 0.6934657692909241; accuracy of 0.4973684251308441; AUROC of 0.5365015864372253; AUPRC of 0.5551764965057373; TP of 27.0\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 2: Loss of 0.6933785676956177; accuracy of 0.5157894492149353; AUROC of 0.5075069069862366; AUPRC of 0.5071339011192322; TP of 278.0\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 3: Loss of 0.6981106996536255; accuracy of 0.49210527539253235; AUROC of 0.5970429182052612; AUPRC of 0.5717699527740479; TP of 0.0\n",
      "------------------------------------------------------------------------\n",
      "Score for fold 4: Loss of 0.6884648203849792; accuracy of 0.5605263113975525; AUROC of 0.5289491415023804; AUPRC of 0.4773809313774109; TP of 0.0\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 0.693438196182251 (+- 0.0030555494497595983)\n",
      "> Auroc: 0.5351725697517395\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "# Define metric containers\n",
    "loss_list = []\n",
    "accuracy_list = []\n",
    "auroc_list = []\n",
    "auprc_list = []\n",
    "true_positive_list = []\n",
    "\n",
    "for i, (train_index, validation_index) in enumerate(group_kfold.split(X, Y, groups)):\n",
    "\tx_train = X[train_index]\n",
    "\ty_train = Y[train_index]\n",
    "\n",
    "\tx_val = X[validation_index]\n",
    "\ty_val = Y[validation_index]\n",
    "\n",
    "\tmodel = get_model(input_shape=input_shape, perform_evoaug=True, augment_list=augment_list, learning_rate=0.001)\n",
    "\n",
    "\t# We add validation here, because one of the callbacks relies on val_loss metric\n",
    "\tmodel.fit(x_train,\n",
    "\t\t\ty_train,\n",
    "\t\t\tepochs=100,\t\n",
    "\t\t\tbatch_size=100,\n",
    "\t\t\tvalidation_data=(x_val, y_val),\n",
    "\t\t\tcallbacks=callbacks\n",
    "\t\t\t)\n",
    "\tscores = model.evaluate(x_val, y_val, verbose=0)\n",
    "\tprint(f'Score for fold {i}: Loss of {scores[0]}; accuracy of {scores[1]}; auroc of {scores[2]}; auprc of {scores[3]}; TP of {scores[4]}')\n",
    "\t\n",
    "\tloss_list.append(scores[0])\n",
    "\taccuracy_list.append(scores[1])\n",
    "\tauroc_list.append(scores[2])\n",
    "\tauprc_list.append(scores[3])\n",
    "\ttrue_positive_list.append(scores[4])\n",
    "\t\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(loss_list)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Score for fold {i}: Loss of {loss_list[i]}; accuracy of {accuracy_list[i]}; AUROC of {auroc_list[i]}; AUPRC of {auprc_list[i]}; TP of {true_positive_list[i]}')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Loss: {np.mean(loss_list)} (+- {np.std(loss_list)})')\n",
    "print(f'> Auroc: {np.mean(auroc_list)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a model on all the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 25s 341ms/step - loss: 0.6952 - acc: 0.4913 - auROC: 0.4859 - auPRC: 0.4793 - true_positives_23: 784.0000\n"
     ]
    }
   ],
   "source": [
    "model = get_model(input_shape=input_shape, perform_evoaug=True, augment_list=augment_list, learning_rate=0.001)\n",
    "history = model.fit(X,\n",
    "\t\t\t\t\tY,\n",
    "\t\t\t\t\tepochs=100,\n",
    "\t\t\t\t\tbatch_size=100,\n",
    "\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform post-hoc conjoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = get_siamese_model(model.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the test set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.stack(test_df[\"One_hot_encoded\"])\n",
    "x_test_rc = np.stack(test_df[\"RC_one_hot_encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[\"Label\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we used evo aug in our model all the sequences which were trained on, were of length 620. We use the evoaug padding function to pad the test set to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = model._pad_end(x_test)\n",
    "x_test_rc = model._pad_end(x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_categories, predictions = post_hoc_conjoining(siamese_model, x_test, x_test_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053068609553966"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auroc(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
